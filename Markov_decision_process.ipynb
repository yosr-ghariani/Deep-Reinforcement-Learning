{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia8lTalyK2IV"
      },
      "outputs": [],
      "source": [
        "\"\"\"A simple world model\n",
        "\n",
        "Simple deterministic MDP is made of 6 grids (states)\n",
        "---------------------------------\n",
        "|         |          |          |\n",
        "|  Start  |          |  Goal    |\n",
        "|         |          |          |\n",
        "---------------------------------\n",
        "|         |          |          |\n",
        "|         |          |  Hole    |\n",
        "|         |          |          |\n",
        "---------------------------------\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "class QWorld:\n",
        "    def __init__(self):\n",
        "        \"\"\"Simulated deterministic world made of 6 states.\n",
        "        \"\"\"\n",
        "        # 4 actions\n",
        "        # 0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "        self.col = 4\n",
        "\n",
        "        # 6 states\n",
        "        self.row = 6\n",
        "\n",
        "        # setup the environment\n",
        "        self.init_transition_table()\n",
        "        self.init_reward_table()\n",
        "\n",
        "        # reset the environment\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"start of episode\"\"\"\n",
        "        self.state = 0\n",
        "        self.count = 0\n",
        "        return self.state\n",
        "\n",
        "    def is_in_win_state(self):\n",
        "        \"\"\"agent wins when the goal is reached\"\"\"\n",
        "        return self.state == 2\n",
        "\n",
        "\n",
        "    def init_reward_table(self):\n",
        "        \"\"\"\n",
        "        0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "        ----------------\n",
        "        | 0 | 0 | 100  |\n",
        "        ----------------\n",
        "        | 0 | 0 | -100 |\n",
        "        ----------------\n",
        "        \"\"\"\n",
        "        #############################################\n",
        "        #TODO-- fill in the reward table\n",
        "        #############################################\n",
        "        self.reward_table = np.zeros([self.row, self.col])\n",
        "        # To be completed\n",
        "        self.reward_table[1,2] = 100 #[state 1, action 2 (right)] = reward 100\n",
        "        self.reward_table[4,2] = -100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def init_transition_table(self):\n",
        "        \"\"\"\n",
        "        actions:\n",
        "        0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "\n",
        "        states:\n",
        "        -------------\n",
        "        | 0 | 1 | 2 |\n",
        "        -------------\n",
        "        | 3 | 4 | 5 |\n",
        "        -------------\n",
        "        \"\"\"\n",
        "        self.transition_table = np.zeros([self.row, self.col],\n",
        "                                         dtype=int)\n",
        "\n",
        "        self.transition_table[0, 0] = 0 #[state 0, action 0 (left)] = state 0 (stays in place)\n",
        "        self.transition_table[0, 1] = 3\n",
        "        self.transition_table[0, 2] = 1\n",
        "        self.transition_table[0, 3] = 0\n",
        "\n",
        "        #############################################\n",
        "        #TODO-- complete the transition_table\n",
        "        #############################################\n",
        "        # to be completed\n",
        "\n",
        "        self.transition_table[1, 0] = 0\n",
        "        self.transition_table[1, 1] = 4\n",
        "        self.transition_table[1, 2] = 2\n",
        "        self.transition_table[1, 3] = 1\n",
        "\n",
        "        self.transition_table[2, 0] = 1\n",
        "        self.transition_table[2, 1] = 5\n",
        "        self.transition_table[2, 2] = 2\n",
        "        self.transition_table[2, 3] = 2\n",
        "\n",
        "        self.transition_table[3, 0] = 3\n",
        "        self.transition_table[3, 1] = 3\n",
        "        self.transition_table[3, 2] = 4\n",
        "        self.transition_table[3, 3] = 0\n",
        "\n",
        "        self.transition_table[4, 0] = 3\n",
        "        self.transition_table[4, 1] = 4\n",
        "        self.transition_table[4, 2] = 5\n",
        "        self.transition_table[4, 3] = 1\n",
        "\n",
        "        self.transition_table[5, 0] = 4\n",
        "        self.transition_table[5, 1] = 5\n",
        "        self.transition_table[5, 2] = 5\n",
        "        self.transition_table[5, 3] = 2\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"execute the action on the environment\n",
        "        Argument:\n",
        "            action (tensor): An action in Action space\n",
        "        Returns:\n",
        "            next_state (tensor): next env state\n",
        "            reward (float): reward received by the agent\n",
        "            done (Bool): whether the terminal state\n",
        "                is reached\n",
        "        \"\"\"\n",
        "        # determine the next_state given state and action\n",
        "        next_state = self.transition_table[self.state, action]\n",
        "        # done is True if next_state is Goal or Hole\n",
        "        done =  next_state in [2,5] # reward in state 2 and hole in state 5\n",
        "\n",
        "        # reward given the state and action\n",
        "        reward = self.reward_table[self.state, action]\n",
        "        # the enviroment is now in new state\n",
        "        self.state = next_state\n",
        "        self.count+=1\n",
        "        return next_state, reward, done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def print_cell(self, row=0):\n",
        "        \"\"\"UI to display agent moving on the grid\"\"\"\n",
        "        print(\"\")\n",
        "        for i in range(13):\n",
        "            j = i - 2\n",
        "            if j in [0, 4, 8]:\n",
        "                if j == 8:\n",
        "                    if self.state == 2 and row == 0:\n",
        "                        marker = \"\\033[4mG\\033[0m\"\n",
        "                    elif self.state == 5 and row == 1:\n",
        "                        marker = \"\\033[4mH\\033[0m\"\n",
        "                    else:\n",
        "                        marker = 'G' if row == 0 else 'H'\n",
        "                    color = self.state == 2 and row == 0\n",
        "                    color = color or (self.state == 5 and row == 1)\n",
        "                    color = 'red' if color else 'blue'\n",
        "                    print(colored(marker, color), end='')\n",
        "                elif self.state in [0, 1, 3, 4]:\n",
        "                    cell = [(0, 0, 0), (1, 0, 4), (3, 1, 0), (4, 1, 4)]\n",
        "                    marker = '_' if (self.state, row, j) in cell else ' '\n",
        "                    print(colored(marker, 'red'), end='')\n",
        "                else:\n",
        "                    print(' ', end='')\n",
        "            elif i % 4 == 0:\n",
        "                    print('|', end='')\n",
        "            else:\n",
        "                print(' ', end='')\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "    def print_world(self, action):\n",
        "        \"\"\"UI to display mode and action of agent\"\"\"\n",
        "        actions = { 0: \"(Left)\", 1: \"(Down)\", 2: \"(Right)\", 3: \"(Up)\" }\n",
        "        if self.count==0:\n",
        "          print(\"Start Game\")\n",
        "        else:\n",
        "          print(\"Action : \", actions[action])\n",
        "        for _ in range(13):\n",
        "            print('-', end='')\n",
        "        self.print_cell()\n",
        "        for _ in range(13):\n",
        "            print('-', end='')\n",
        "        self.print_cell(row=1)\n",
        "        for _ in range(13):\n",
        "            print('-', end='')\n",
        "        print(\"\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_episode(episode, delay=1):\n",
        "    \"\"\"UI to display episode count\n",
        "    Arguments:\n",
        "        episode (int): episode number\n",
        "        delay (int): sec delay\n",
        "\n",
        "    \"\"\"\n",
        "    os.system('clear')\n",
        "    for _ in range(13):\n",
        "        print('=', end='')\n",
        "    print(\"\")\n",
        "    print(\"Episode \", episode)\n",
        "    for _ in range(13):\n",
        "        print('=', end='')\n",
        "    print(\"\")\n",
        "    time.sleep(delay)\n",
        "\n",
        "def print_status(q_world, done,action, delay=1):\n",
        "    \"\"\"UI to display the world,\n",
        "        delay of 1 sec for ease of understanding\n",
        "    \"\"\"\n",
        "    os.system('clear')\n",
        "    q_world.print_world(action)\n",
        "    if done:\n",
        "        print(\"-------EPISODE DONE--------\")\n",
        "        delay *= 2\n",
        "    time.sleep(delay)"
      ],
      "metadata": {
        "id": "xM3FVC9cYlwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate the environment\n",
        "q_world = QWorld()\n"
      ],
      "metadata": {
        "id": "tCYOCOPBK7YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TODO:**\n",
        "\n",
        "\n",
        "implementing each of the following situations in a separate cell.\n",
        "\n",
        "**Situation 1:**take agent to goal in 2 steps. Print the episode name and display the grid for each step taken.\n",
        "\n",
        "**Situation 2:** take agent to H in 3 steps. Print the episode name and display the grid for each step taken.\n",
        "\n",
        "**Situation 3:** implement the following trajectory: down-right-up-right. what's the cumulative reward (assume the discount factor is 1)? Compare with the cumulative reward of the episode from **Situation 1** and comment.\n",
        "Make sure the cumulative reward is printed when the cell is executed.\n",
        "\n",
        "**Situation 4:** Implement an agent that takes random actions at each step and stops only when the task is solved (note that your agent may need to go through multiple episodes before your it is able to reach the goal). After how many episodes it solved the task? (the number of episodes should be displayed automatically each time you run the cell)"
      ],
      "metadata": {
        "id": "CwvXZezFg2js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Situation 1\n",
        "# print initial grid --before taking any action--\n",
        "state = q_world.reset()\n",
        "done = False\n",
        "episode = 1\n",
        "delay = 0\n",
        "print_episode(episode=episode, delay=0)\n",
        "\n",
        "# print initial status of the board\n",
        "print_status(q_world, done, 0, delay=delay)\n",
        "\n",
        "cummul=0\n",
        "# to take the agent to GOAL (G) in two steps, the agent needs\n",
        "# to go right then go right again\n",
        "\n",
        "# recall the actions:\n",
        "# 0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "\n",
        "# 1- Go right\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "cummul+=reward\n",
        "\n",
        "# 1- Go right again\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "\n",
        "cummul+=reward\n",
        "print (\"cummulative reward\",cummul)"
      ],
      "metadata": {
        "id": "oUjj7jPFVSlU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757d95d8-98cb-43f9-bf40-ec59af2790ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  1\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "cummulative reward 0.0\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | \u001b[4mG\u001b[0m |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "cummulative reward 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Situation 2\n",
        "# TODO\n",
        "# print initial grid --before taking any action--\n",
        "state = q_world.reset()\n",
        "done = False\n",
        "episode = 2\n",
        "delay = 0\n",
        "print_episode(episode=episode, delay=0)\n",
        "\n",
        "# print initial status of the board\n",
        "print_status(q_world, done, 0, delay=delay)\n",
        "\n",
        "\n",
        "# to take the agent to the hole(H) in 3 steps, the agent needs\n",
        "# to go right, down then go right again\n",
        "\n",
        "# recall the actions:\n",
        "# 0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "\n",
        "# 1- Go right\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "\n",
        "# 2- Go down\n",
        "action=1\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "\n",
        "# 3- Go right again\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n"
      ],
      "metadata": {
        "id": "4JY-_Hm9MD6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abe3a38-28ed-4a53-a191-b46a37105c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  2\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   |   | \u001b[4mH\u001b[0m |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Situation 3\n",
        "# TODO\n",
        "# print initial grid --before taking any action--\n",
        "state = q_world.reset()\n",
        "done = False\n",
        "episode = 3\n",
        "delay = 0\n",
        "print_episode(episode=episode, delay=0)\n",
        "\n",
        "# print initial status of the board\n",
        "print_status(q_world, done, 0, delay=delay)\n",
        "\n",
        "cummul=0\n",
        "# to take the agent to the hole(H) in 3 steps, the agent needs\n",
        "# to go down,right,up,right\n",
        "\n",
        "# recall the actions:\n",
        "# 0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "\n",
        "# 1- Go down\n",
        "action=1\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "cummul+=reward\n",
        "\n",
        "# 2- Go right\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "cummul+=reward\n",
        "\n",
        "# 3- Go up\n",
        "action=3\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "cummul+=reward\n",
        "\n",
        "# 4- Go right again\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "cummul+=reward\n",
        "\n",
        "print(\"cummulative reward\",cummul)"
      ],
      "metadata": {
        "id": "D7pnyph8iITn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3395f264-b4e9-4542-fd0e-8a62b92bc100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  3\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | \u001b[4mG\u001b[0m |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**: The cummulative reward of both the 1st and 3rd situations are equal since it is a sparse reward system (neutral reward signals with reward equal to zero)"
      ],
      "metadata": {
        "id": "0nhL87nqdAHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random as r\n",
        "# Implement Situation 4\n",
        "# TODO\n",
        "# print initial grid --before taking any action--\n",
        "solved=False\n",
        "total_eps=0\n",
        "while solved !=True:\n",
        "  state = q_world.reset()\n",
        "  done = False\n",
        "  total_eps += 1\n",
        "  delay = 0\n",
        "  print_episode(episode=total_eps, delay=0)\n",
        "\n",
        "  # print initial status of the board\n",
        "  print_status(q_world, done, 0, delay=delay)\n",
        "\n",
        "\n",
        "  # random actions till end of game\n",
        "\n",
        "  # recall the actions:\n",
        "  # 0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "\n",
        "  while done!=True:\n",
        "    action=r.randint(0,3)\n",
        "    next_state, reward, done = q_world.step(action)\n",
        "    print_status(q_world, done,action, delay=delay)\n",
        "  if next_state==2:\n",
        "    solved=True\n",
        "\n",
        "print(\"total number of episodes: \", total_eps)\n",
        "\n"
      ],
      "metadata": {
        "id": "jdApmbmYXWdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8cc6d15-8808-4102-d816-134825fe3681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  1\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   |   | \u001b[4mH\u001b[0m |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "=============\n",
            "Episode  2\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   |   | \u001b[4mH\u001b[0m |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "=============\n",
            "Episode  3\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | \u001b[4mG\u001b[0m |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "total number of episodes:  3\n"
          ]
        }
      ]
    }
  ]
}